# -*- coding: utf-8 -*-
"""MODEL TENSORFLOW DENSE - KLASIFIKASI RISIKO KEHAMILAN IBU HAMIL

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GTYWbvtn7YBgK9laY7qzkf88i9tFY7jQ
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.models import load_model
import joblib
from imblearn.over_sampling import SMOTE
from sklearn.utils.class_weight import compute_class_weight

df = pd.read_csv("/content/Dataset - Updated.csv")
df.head()

df.info()

# Select only numerical columns for plotting
numerical_cols = df.select_dtypes(include=np.number).columns

# Create histograms for numerical features
df[numerical_cols].hist(bins=20, figsize=(15, 10))
plt.tight_layout()
plt.show()

# Create box plots for numerical features
plt.figure(figsize=(15, 10))
sns.boxplot(data=df[numerical_cols])
plt.title("Box Plots of Numerical Features")
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Create pairplot for numerical features (can be slow with many columns)
if len(numerical_cols) < 10: # Avoid plotting too many columns
    sns.pairplot(df[numerical_cols])
    plt.show()
else:
    print("Skipping pairplot due to large number of numerical columns.")

# Correlation heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(df[numerical_cols].corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap of Numerical Features")
plt.show()

df.drop_duplicates(inplace=True)
df.dropna(inplace=True)
df.isna().sum()

df.dtypes

df.info()

print(df['Mental Health'].value_counts())

# Plot the distribution of the 'Risk Level' column
plt.figure(figsize=(8, 6))
sns.countplot(x='Mental Health', data=df)
plt.title('Distribution of Mental Health')
plt.xlabel('Mental Health')
plt.ylabel('Count')
plt.show()

# Encode target
le = LabelEncoder()
df['Risk Level'] = le.fit_transform(df['Risk Level'])

# Split features and target
X = df.drop('Risk Level', axis=1)
y = df['Risk Level']

# Train-validation split
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)

# Build model
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(3, activation='softmax')  # 3 kelas: Low, Medium, High
])

# Compile
model.compile(
    optimizer=tf.keras.optimizers.Adamax(learning_rate=0.005),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2)

# Plot accuracy
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# Plot loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

# Predict on validation set
y_pred_probs = model.predict(X_val)
y_pred_labels = np.argmax(y_pred_probs, axis=1)

# Convert class labels back to strings using the fitted label encoder's classes
# This ensures we only use the labels the encoder was trained on.
target_names = le.classes_

# Print classification report
from sklearn.metrics import classification_report
print(classification_report(y_val, y_pred_labels, target_names=target_names))

# For the confusion matrix as well, use the correct target names
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_val, y_pred_labels)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=target_names, yticklabels=target_names)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# prompt: saved model dan joblib

# Save the trained Keras model
model.save('/content/mental_health_risk_model.h5')

# Save the StandardScaler
joblib.dump(scaler, '/content/scaler.pkl')

# Save the LabelEncoder
joblib.dump(le, '/content/label_encoder.pkl')

print("Model, scaler, and label encoder saved successfully.")